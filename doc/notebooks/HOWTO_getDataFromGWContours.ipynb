{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO obtain archival ESO data over the area covered by a GW event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ESOAsg.ancillary import astro\n",
    "from ESOAsg.ancillary import polygons\n",
    "from ESOAsg import archive_observations\n",
    "from ESOAsg import archive_science_portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get credibility contours for a GW event\n",
    "\n",
    "To begin, you need to have on your disk a `bayestar.fits.gz` maps associated to a GW superevent (see [Singer and Price, 2016](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.93.024013) for more details on `BAYESTAR`). This is necessary to extract the probability contours for the event you would like to explore.\n",
    "\n",
    "If not, you can download it from [gracedb.ligo.org](https://gracedb.ligo.org/) using:\n",
    "```python\n",
    "astro.download_gw_bayestar(super_event_name)\n",
    "```\n",
    "\n",
    "Where, for this example: `super_event_name='S191205ah'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO]    ::\u001b[0m File S191205ah_bayestar.fits.gz successfully downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_event_name = 'S191205ah'\n",
    "astro.download_gw_bayestar(super_event_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can extract the contours associated to a given `credible_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO]    ::\u001b[0m Extracted the contours for 3 regions at 50.0 credible level\n"
     ]
    }
   ],
   "source": [
    "credible_level = 50.\n",
    "contours = astro.contours_from_gw_bayestar(super_event_name+'_bayestar.fits.gz', \n",
    "                                           credible_level=credible_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check the result using:\n",
    "```python\n",
    "astro.show_contours_from_gw_bayestar(bayestar_file, contours=contours)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro.show_contours_from_gw_bayestar(super_event_name+'_bayestar.fits.gz', contours=contours,\n",
    "                                     cmap='afmhot', contours_color='white', show_figure=True, \n",
    "                                     save_figure=super_event_name+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the ESO Archive to collect data withing the contours\n",
    "\n",
    "Now it is time to run the proper query to the Archive to obtain all data located within the contour regions. To do this you have two options:\n",
    "* [Archive Science Portal](http://archive.eso.org/scienceportal/home)\n",
    "* [Programmatic access](http://archive.eso.org/programmatic/)\n",
    "\n",
    "There is, however, one last step before doing this. You need to convert the contours into polygons. This is done with:\n",
    "```python\n",
    "archive_observations.contours_to_polygons(contours, max_vertices=30)\n",
    "```\n",
    "where `max_vertices` is set to avoid crashes due to polygons with too many vertices in the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = polygons.contours_to_polygons(contours, max_vertices=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `polygons` is a list with N elements (with N matching the number of contours). Each elements contains a string defining the location in the sky of the polygon with RA, Dec, seprated by commas and with the first RA, Dec pair that matches the last one (to close the polygon). For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'167.8711, -2.5374, 166.9922, -2.0894, 166.1133, -1.3430, 165.9375, -0.5968, 165.7617, 0.1492, 165.5859, 0.8953, 165.4102, 1.6415, 165.2344, 2.3880, 165.7617, 3.1349, 166.2891, 3.8824, 166.4648, 4.6305, 166.6406, 5.3794, 167.5195, 5.8292, 168.3984, 5.6792, 169.2773, 4.9300, 169.4531, 4.1815, 169.6289, 3.4338, 169.8047, 2.6867, 169.6289, 1.9401, 169.4531, 1.1938, 169.2773, 0.4476, 169.1016, -0.2984, 168.9258, -1.0445, 168.7500, -1.7908, 167.8711, -2.5374'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive Science Portal Query:\n",
    "After running:\n",
    "```python\n",
    "archive_observations.query_ASP_from_polygons(polygons=polygons, open_link=True)\n",
    "```\n",
    "you should see different ASP pages opening in your broswer (one per polygon) pointing to the different regions of the sky you are quering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_science_portal.query_from_polygons(polygons=polygons, open_link=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic access:\n",
    "```python\n",
    "archive_observations.query_TAP_from_polygons(polygons=polygons)\n",
    "```\n",
    "returns the result of the query:\n",
    "```SQL\n",
    "SELECT\n",
    "   target_name, dp_id, s_ra, s_dec, t_exptime, em_min, em_max, \n",
    "   dataproduct_type, instrument_name, abmaglim, proposal_id\n",
    "FROM\n",
    "   ivoa.ObsCore\n",
    "WHERE\n",
    "   intersects(s_region, POLYGON('', `polygon`)) = 1\n",
    "```\n",
    "for convenince `maxrec` is set to `2` so only the first two results are returned, but you may want to increase this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[WORKING] ::\u001b[0m Running query 1 to the ESO archive (out of 3 total)\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m A total of 2 entries has been retrieved (with maxrec=2)\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m For the following instrument:\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m  - VIRCAM\n",
      "\u001b[1;30m[WORKING] ::\u001b[0m Running query 2 to the ESO archive (out of 3 total)\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m A total of 2 entries has been retrieved (with maxrec=2)\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m For the following instrument:\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m  - OMEGACAM\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m  - OMEGACAM, VIRCAM\n",
      "\u001b[1;30m[WORKING] ::\u001b[0m Running query 3 to the ESO archive (out of 3 total)\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m A total of 2 entries has been retrieved (with maxrec=2)\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m For the following instrument:\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m  - UVES\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m  - VIRCAM\n"
     ]
    }
   ],
   "source": [
    "result_from_query = archive_observations.query_from_polygons(polygons=polygons, maxrec=2, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now you can download the data by exploring the `dp_id` of the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO]    ::\u001b[0m Your disk has:\n",
      "\u001b[1;32m[INFO]    ::\u001b[0m Total: 465.72 GB, Used: 465.72 GB, Free: 465.72 GB\n",
      "\u001b[1;30m[WORKING] ::\u001b[0m Retrieving file ADP.2014-10-17T13:56:17.997.fits\n"
     ]
    }
   ],
   "source": [
    "archive_observations.download(result_from_query[0]['dp_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in one\n",
    "The same resuls are achievable with the (un-official) ESOAsg script:\n",
    "[`get_data_from_gw_event`](https://esoasg.readthedocs.io/en/latest/archive_scripts.html#get-data-from-gw-event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
